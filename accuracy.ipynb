{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from dateutil.parser import parse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from fuzzywuzzy import fuzz\n",
    "import unicodedata\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# ------------------- Normalization Functions -------------------\n",
    "def normalize_language(lang):\n",
    "    lang = lang.lower().strip()\n",
    "    lang_map = {\"english\": \"en\", \"eng\": \"en\", \"en\": \"en\", \"english (us)\": \"en\"}\n",
    "    return lang_map.get(lang, lang)\n",
    "\n",
    "def normalize_date(date_str):\n",
    "    try:\n",
    "        return parse(date_str, fuzzy=True).date().isoformat()\n",
    "    except:\n",
    "        return date_str.strip().lower()\n",
    "\n",
    "def normalize_format_genre(val):\n",
    "    genre_map = {\n",
    "        \"text\": \"text\",\n",
    "        \"printed book\": \"book\",\n",
    "        \"book\": \"book\",\n",
    "        \"journal\": \"journal\",\n",
    "        \"memo\": \"memorandum\",\n",
    "        \"memorandum\": \"memorandum\",\n",
    "        \"questionnaire\": \"questionnaire\",\n",
    "        \"questionares\": \"questionnaire\",\n",
    "        \"draft\": \"draft\",\n",
    "        \"correspondence\": \"correspondence\",\n",
    "        \"letter\": \"correspondence\",\n",
    "        \"email\": \"correspondence\",\n",
    "        \"agenda\": \"agenda\",\n",
    "        \"meeting agenda\": \"agenda\",\n",
    "        \"testimony\": \"testimony\",\n",
    "        \"summary\": \"summary\",\n",
    "        \"biography\": \"biography\",\n",
    "        \"biographies\": \"biography\",\n",
    "        \"list\": \"list\",\n",
    "        \"note\": \"note\",\n",
    "        \"notes\": \"note\",\n",
    "        \"photograph\": \"photograph\",\n",
    "        \"photo\": \"photograph\",\n",
    "        \"image\": \"photograph\",\n",
    "        \"document\": \"document\",\n",
    "        \"report\": \"report\",\n",
    "        \"transcript\": \"transcript\",\n",
    "        \"presentation\": \"presentation\",\n",
    "        \"speech\": \"speech\",\n",
    "        \"form\": \"form\",\n",
    "        \"proposal\": \"proposal\",\n",
    "        \"policy document\": \"policy document\",\n",
    "        \"executive order\": \"executive order\",\n",
    "        \"press release\": \"press release\",\n",
    "        \"talking points\": \"talking points\",\n",
    "        \"meeting minutes\": \"meeting minutes\",\n",
    "        \"lecture series\": \"lecture\",\n",
    "        \"course description\": \"lecture\",\n",
    "        \"budget document\": \"budget document\",\n",
    "        \"outline\": \"outline\",\n",
    "        \"routing slip\": \"routing slip\",\n",
    "        \"event\": \"event\",\n",
    "        \"ceremony\": \"event\",\n",
    "        \"fax\": \"fax\"\n",
    "    }\n",
    "\n",
    "    # Split on delimiters and normalize each part\n",
    "    parts = re.split(r'[|;,/]', str(val).lower())\n",
    "    normalized = [genre_map.get(part.strip(), part.strip()) for part in parts if part.strip()]\n",
    "\n",
    "    # Deduplicate and sort for consistent comparison\n",
    "    return \" | \".join(sorted(set(normalized)))\n",
    "\n",
    "\n",
    "def normalize_entity(e):\n",
    "    return re.sub(r\"[^\\w\\s]\", \"\", e.lower()).strip()\n",
    "\n",
    "# ------------------- Matching Functions -------------------\n",
    "def clean_entities(entity_list):\n",
    "    if isinstance(entity_list, str):\n",
    "        entity_list = [entity_list]\n",
    "    \n",
    "    PAREN_REGEX = re.compile(r\"\\(.*?\\)\")\n",
    "    SPACE_REGEX = re.compile(r\"\\s+\")\n",
    "    \n",
    "    def normalize_entity_string(entity_string):\n",
    "        raw_entities = entity_string.split(\"|\")\n",
    "        cleaned = []\n",
    "        \n",
    "        for raw in raw_entities:\n",
    "            e = raw.strip()\n",
    "            \n",
    "            # Handle \"Last, First\" only if no conjunctions\n",
    "            if ',' in e and ' and ' not in e:\n",
    "                parts = [p.strip() for p in e.split(',')]\n",
    "                if len(parts) >= 2:\n",
    "                    e = f\"{' '.join(parts[1:])} {parts[0]}\"\n",
    "            \n",
    "            e = PAREN_REGEX.sub(\"\", e)\n",
    "            e = SPACE_REGEX.sub(\" \", e).strip().lower()\n",
    "            e = unicodedata.normalize('NFKD', e).encode('ascii', 'ignore').decode('ascii')\n",
    "            \n",
    "            if e:\n",
    "                cleaned.append(e)\n",
    "        return cleaned\n",
    "    \n",
    "    return [\n",
    "        normalized\n",
    "        for entry in entity_list\n",
    "        if isinstance(entry, str) and entry.strip()\n",
    "        for normalized in normalize_entity_string(entry)\n",
    "    ]\n",
    "\n",
    "def entity_recall_match(gt_list, bm_list, recall_threshold=0.70, fuzzy_threshold=60):\n",
    "    gt_clean = clean_entities(gt_list)\n",
    "    print(gt_clean)\n",
    "    bm_clean = clean_entities(bm_list)\n",
    "    print(bm_clean)\n",
    "\n",
    "    if not gt_clean:\n",
    "        return False\n",
    "    \n",
    "    match_count = 0\n",
    "    for gt_entity in gt_clean:\n",
    "        # Check if any benchmark entity matches this ground truth entity\n",
    "        for bm_entity in bm_clean:\n",
    "            if fuzz.token_set_ratio(gt_entity, bm_entity) >= fuzzy_threshold:\n",
    "                match_count += 1\n",
    "                break\n",
    "\n",
    "    recall = match_count / len(gt_clean)\n",
    "    return recall >= recall_threshold\n",
    "\n",
    "def tokenize(text):\n",
    "    return set(re.findall(r\"\\w+\", text.lower()))\n",
    "\n",
    "def token_recall_match(gt, bm, threshold=0.70):\n",
    "    tokens_gt = tokenize(gt)\n",
    "    tokens_bm = tokenize(bm)\n",
    "    if not tokens_gt:\n",
    "        return False\n",
    "    recall = len(tokens_gt & tokens_bm) / len(tokens_gt)\n",
    "    return recall >= threshold\n",
    "\n",
    "def cosine_match(gt, bm, threshold=0.70):\n",
    "    if not gt.strip() or not bm.strip():\n",
    "        return False\n",
    "    emb_gt = model.encode(gt, convert_to_tensor=True)\n",
    "    emb_bm = model.encode(bm, convert_to_tensor=True)\n",
    "    score = cosine_similarity(emb_gt.cpu().numpy().reshape(1, -1),\n",
    "                              emb_bm.cpu().numpy().reshape(1, -1))[0][0]\n",
    "    return score >= threshold\n",
    "\n",
    "def fuzzy_match(gt, bm, threshold=0.70):\n",
    "    if not gt.strip() or not bm.strip():\n",
    "        return False\n",
    "    ratio = SequenceMatcher(None, gt.lower(), bm.lower()).ratio()\n",
    "    return ratio >= threshold\n",
    "\n",
    "# ------------------- Field-Based Matching Dispatcher -------------------\n",
    "def match_field(gt_val, bm_val, field):\n",
    "    if field in [\"Title\", \"Description\", \"Subject\", \"People and Organizations\", \"Format Genre\"]:\n",
    "        return entity_recall_match(gt_val, bm_val, recall_threshold=0.70, fuzzy_threshold=60)\n",
    "    elif field == \"Language\":\n",
    "        return normalize_language(gt_val) == normalize_language(bm_val)\n",
    "    elif field == \"Date\":\n",
    "        return normalize_date(gt_val) == normalize_date(bm_val)\n",
    "    elif field in [\"Publisher\", \"Accessibility Summary\"]:\n",
    "        if not gt_val.strip() and bm_val.strip() == \"Null\":\n",
    "            return True\n",
    "        else:\n",
    "            return entity_recall_match(gt_val, bm_val, recall_threshold=0.70, fuzzy_threshold=70)\n",
    "    else:\n",
    "        return gt_val.strip().lower() == bm_val.strip().lower()\n",
    "\n",
    "# ------------------- Main Comparison Function -------------------\n",
    "def compare_csvs_custom(gt_df, benchmark_df, columns_to_compare,\n",
    "                        gt_id_col=\"Quartex Name\", bm_id_col=\"Unique_ID\"):\n",
    "\n",
    "    merged_df = pd.merge(gt_df, benchmark_df, left_on=gt_id_col, right_on=bm_id_col, suffixes=('_gt', '_bm'))\n",
    "    results = []\n",
    "\n",
    "    for col in columns_to_compare:\n",
    "        gt_col_name = f\"{col}_gt\"\n",
    "        bm_col_name = f\"{col}_bm\"\n",
    "\n",
    "        if gt_col_name not in merged_df.columns or bm_col_name not in merged_df.columns:\n",
    "            results.append({\"Column\": col, \"Match %\": \"Column missing\", \"Matches\": 0, \"Total\": 0})\n",
    "            continue\n",
    "\n",
    "        gt_col = merged_df[gt_col_name].fillna(\"\").astype(str)\n",
    "        bm_col = merged_df[bm_col_name].fillna(\"\").astype(str)\n",
    "\n",
    "        matches = sum(match_field(gt_val, bm_val, col) for gt_val, bm_val in zip(gt_col, bm_col))\n",
    "        total = len(gt_col)\n",
    "        match_percent = round(matches / total * 100, 2) if total > 0 else 0\n",
    "\n",
    "        results.append({\"Column\": col, \"Match %\": match_percent, \"Matches\": matches, \"Total\": total})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ------------------- Main Execution -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    ground_truth_df = pd.read_csv(\"ground_truth.csv\")\n",
    "    benchmark_df = pd.read_csv(\"mistral_gemini_benchmark.csv\")\n",
    "\n",
    "    ground_truth_df.columns = ground_truth_df.columns.str.strip()\n",
    "    benchmark_df.columns = benchmark_df.columns.str.strip()\n",
    "\n",
    "    columns = [\n",
    "        \"Title\",\n",
    "        \"People and Organizations\",\n",
    "        \"Description\",\n",
    "        \"Language\",\n",
    "        \"Publisher\",\n",
    "        \"Date\",\n",
    "        \"Subject\",\n",
    "        \"Format Genre\",\n",
    "        \"Accessibility Summary\"\n",
    "    ]\n",
    "\n",
    "    results_df = compare_csvs_custom(\n",
    "        ground_truth_df,\n",
    "        benchmark_df,\n",
    "        columns,\n",
    "        gt_id_col=\"Quartex Name\",\n",
    "        bm_id_col=\"Unique_ID\"\n",
    "    )\n",
    "\n",
    "    print(results_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_1.8.0_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
